---
title:: How to Audit an SEO Agency When You're Not an SEO Expert
focus_keyword:: SEO agency audit
word_count_target:: 2,500
status:: draft
created:: 2026.01.19
type:: pillar article
framework:: Koray Contextual Vector
---

# How to Audit an SEO Agency When You're Not an SEO Expert

Your agency sends a 47-page monthly report. It contains **domain authority** scores, keyword ranking tables, backlink acquisition numbers, and charts showing lines going up. You approve the invoice. You have no idea if the work was good.

This happens constantly. Marketing leaders pay $8,000 to $25,000 monthly for SEO services they can't evaluate. The agency could be doing exceptional work. They could be running a glorified reporting service that moves numbers without moving revenue. You can't tell the difference because SEO expertise isn't your job—but evaluating vendors is.

The audit framework below doesn't require you to become an SEO practitioner. It requires you to ask better questions, verify claims with free tools, and recognize patterns that separate strategic partners from activity-generating machines.

## Red Flags in Agency Reporting

Agency reports reveal more in what they emphasize than what they include. High-performing agencies lead with business impact. Underperformers bury themselves in activity metrics that look impressive but mean nothing.

### Vanity Metrics That Hide Poor Performance

Watch for these reporting patterns that substitute motion for progress.

**Keyword counts without context.** "We now rank for 2,400 keywords" sounds like progress until you examine which keywords. Ranking for 2,400 long-tail queries with 10 monthly searches each generates different value than ranking for 50 high-intent commercial keywords with 5,000 searches each. Ask for keyword ranking reports segmented by search volume and search intent. If the agency resists or can't produce this breakdown, the impressive keyword count is hiding a weak portfolio.

**Domain authority obsession.** **Moz's** **Domain Authority** and **Ahrefs' Domain Rating** are third-party approximations of site strength. They're useful for competitive analysis but worthless as performance metrics. Google doesn't use these scores in its algorithm. An agency celebrating DA increases while traffic stagnates is optimizing for their reporting narrative, not your results.

**Backlink acquisition volume.** "We built 150 links this month" requires immediate follow-up: links from where? A single link from a relevant industry publication with real traffic outweighs 150 links from blog networks, directory spam, or low-quality guest posts. **Ahrefs** or **SEMrush** can show referring domain quality. If the agency won't share backlink sources, or if spot-checking reveals links from sites you've never heard of with no visible traffic, the volume number is meaningless.

**Impression growth without click growth.** **Google Search Console** shows impressions (how often your pages appear in search results) and clicks (how often users click through). Impressions growing while clicks stay flat means you're appearing for queries where users don't choose you. This could indicate ranking improvements for irrelevant keywords, poor meta descriptions, or SERP feature competition. A good agency explains the gap. A weak agency celebrates the impression number and hopes you don't notice.

### "Rankings Improved" Without Traffic or Revenue Increase

This is the most common disconnect in agency reporting, and it reveals fundamental misalignment between agency incentives and client outcomes.

Rankings can improve while business results stay flat or decline for several reasons.

**Keyword cannibalization.** You moved from position 8 to position 4 for one keyword, but dropped from position 3 to position 9 for a related keyword. Net ranking improvement, net traffic decline. Agencies reporting aggregate ranking changes without showing individual keyword movement are hiding this pattern.

**SERP feature displacement.** You rank position 1 for a query, but Google now shows a featured snippet, "People Also Ask" boxes, and a knowledge panel above your result. Your organic CTR collapsed because the SERP changed, not because you did anything wrong. Good agencies track SERP feature presence alongside rankings. Basic agencies don't understand why position 1 doesn't generate the traffic it used to.

**Irrelevant keyword targeting.** You rank higher for keywords that don't match buyer intent. "What is enterprise software" might have 50,000 monthly searches, but searchers asking that question are researching, not buying. If the agency optimized for informational queries while neglecting commercial keywords, ranking improvements don't translate to pipeline.

**Seasonal or external factors.** Traffic dropped because your industry has seasonal patterns, or a competitor launched a massive content campaign, or Google rolled out an algorithm update. Rankings holding steady during a traffic decline might actually represent good defensive work. Context matters.

The red flag isn't ranking improvement with flat traffic—that can happen for legitimate reasons. The red flag is an agency that presents ranking data without acknowledging or explaining the traffic gap.

### Reports That Explain What Was Done But Not Why It Matters

Activity reporting sounds like this: "Optimized 23 title tags. Created 4 blog posts. Submitted disavow file. Fixed 47 crawl errors."

Strategic reporting sounds like this: "Optimized 23 title tags on our highest-traffic commercial pages to improve CTR; initial **Search Console** data shows 12% CTR improvement over the past 14 days. Created 4 blog posts targeting comparison keywords where we previously had no coverage—these keywords represent $180,000 in competitor paid spend annually. Submitted disavow file to address toxic **backlink profile** from previous vendor; expect 6-8 weeks for Google to process. Fixed 47 crawl errors that were preventing Googlebot from accessing our pricing page cluster."

Notice the difference. Activity reports tell you what happened. Strategic reports explain why it matters and connect to business outcomes. If your agency consistently delivers the first type, they're doing tasks. If they deliver the second type, they're executing strategy.

This distinction shows up in reporting format, not just content. Reports organized by deliverable type (technical, content, links) indicate task-oriented thinking. Reports organized by business objective (revenue keywords, competitive gaps, conversion path optimization) indicate strategic alignment.

[INTERNAL: SEO for CMOs—Managing SEO Spend When You Can't Measure It Like Paid]

## Questions to Ask in Monthly Calls

Monthly check-ins default to agency presentations followed by client questions about what was presented. Flip the structure. Come with questions that force strategic conversation instead of activity review.

### "What Didn't Work This Month and What Are You Changing?"

Every month contains experiments that fail. Content that underperforms. Technical fixes that don't move metrics. Link outreach that gets ignored. An agency that reports only wins is either lying or not trying anything ambitious enough to fail.

This question does three things.

First, it surfaces honesty. Agencies that can't discuss failures are managing perception, not results. You want a partner who identifies problems early and adjusts, not one who hides bad news until it's catastrophic.

Second, it reveals strategic thinking. The second half of the question—"what are you changing?"—shows whether the agency learns from setbacks or just moves to the next task. Good agencies have hypotheses about why things failed and plans to address root causes. Weak agencies shrug and say they'll try something different.

Third, it builds trust. When you demonstrate that failure-sharing won't trigger termination, you create space for realistic conversation. Agencies spend enormous energy managing client perception. Releasing that pressure produces better work and more accurate forecasting.

### "How Does This Deliverable Connect to Our Revenue Goals?"

Ask this about specific line items. Not the whole report—individual deliverables.

"You built 40 links this month. How do those links connect to our goal of ranking for commercial keywords in the enterprise segment?"

"You published 6 blog posts. How do those posts connect to our goal of increasing marketing-qualified leads from organic?"

"You fixed site speed issues. How does that connect to our goal of reducing bounce rate on the pricing page?"

These questions force connection between activity and outcome. Some deliverables won't have clean connections—maintenance work, defensive SEO, infrastructure improvements. That's fine if the agency can articulate why the work matters even without direct revenue linkage.

The red flag is deliverables that exist because they're on the contract, not because they advance your goals. If the agency struggles to connect their work to your objectives, the engagement has drifted into task completion rather than strategic partnership.

### "What Would You Do Differently If This Were Your Business?"

This question reveals constraint differences between agency recommendations and owner thinking.

Agency incentives don't perfectly align with client outcomes. Agencies benefit from longer engagements, additional service purchases, and documented activity that justifies retainer fees. Business owners optimize for capital efficiency and outcome achievement.

When you ask "what would you do if this were your business," you're asking the agency to temporarily drop their vendor frame and think like an owner. Their answer might reveal:

**Work they're doing that doesn't matter.** "Honestly, I'd skip the monthly blog posts and redirect that budget to link building. Your content is good enough—distribution is the bottleneck."

**Work they'd do that isn't in scope.** "I'd invest in conversion rate optimization on your landing pages. You're driving traffic, but the pages don't convert. That's not in our SEO scope, but it's limiting returns on our work."

**Strategic pivots they haven't proposed.** "I'd pause new content production and focus on updating your 50 highest-traffic posts. Content decay is killing your performance on established pages."

Good agencies welcome this question because it opens strategic conversation beyond monthly deliverables. Agencies that deflect or give non-answers are comfortable with the task relationship and uncomfortable with strategic accountability.

## Spot-Checking Technical Work You Don't Understand

You don't need to understand technical SEO implementation to verify it happened. Free tools provide sanity checks that keep agencies honest.

### Using Free Tools to Verify Claimed Improvements

**Page speed claims.** Agency says they improved page speed. Go to **Google PageSpeed Insights**, enter your URL, run the test. Compare scores to previous months (you should be tracking this in a simple spreadsheet). If they claim 30% improvement but scores look the same, ask for clarification.

**Indexation claims.** Agency says they fixed crawl errors. Log into **Google Search Console**, go to Pages, look at the Not Indexed reasons. Are the error counts lower than last month? Are the specific errors they mentioned resolved? You can verify this in 60 seconds.

**Ranking claims.** Agency says rankings improved. For important keywords, search them yourself in an incognito window. Note your position. Do this monthly for your top 10-15 target keywords. Basic tracking that doesn't require paid tools.

**Backlink claims.** Agency says they built quality links. Use the free tier of **Ahrefs Webmaster Tools** or **Moz Link Explorer** to see recent backlinks. Click through to a few. Do the linking sites look legitimate? Are they relevant to your industry? Is there visible traffic on those sites?

These checks take 30 minutes monthly. You're not auditing at professional depth—you're running sanity checks that catch obvious discrepancies between claims and reality.

### Asking for Before-and-After Screenshots With Timestamps

For technical work you can't verify yourself, request documentation. Legitimate agencies maintain records of their work. They should be able to produce:

**Crawl reports.** Before-and-after exports from **Screaming Frog** or **Sitebulb** showing which errors existed and which were resolved.

**Speed test archives.** Historical **PageSpeed Insights** or **GTmetrix** reports showing performance before and after optimization work.

**Search Console screenshots.** Time-stamped exports showing coverage status, crawl stats, or Core Web Vitals before and after technical improvements.

**Backlink audit documentation.** For link cleanup work, the disavow file they submitted plus the analysis that identified toxic links for removal.

If an agency can't or won't provide this documentation, one of two things is true: they don't have professional processes for tracking their work, or the work didn't happen as described. Neither reflects well.

### Getting Second Opinions Without Burning the Relationship

You can audit agency work externally without creating adversarial dynamics. Frame it as process improvement, not accusation.

**Annual technical audit from a different vendor.** "We're conducting a technical audit from a fresh perspective. Not a replacement—just want to ensure we're not missing anything." Position it as complementary, not competitive. Good agencies welcome external validation.

**Peer network feedback.** Share your agency's reports (redacted if necessary) with marketing peers who've managed SEO vendors. They'll spot patterns you won't because they've seen dozens of agencies. "Does this reporting format seem typical? Are there questions I should be asking?"

**Consultant review.** Hire an independent SEO consultant for a 2-hour engagement to review three months of agency work. Not to manage the relationship—just to assess quality. Cost is minimal relative to your agency retainer, and the external perspective catches blind spots.

The goal isn't catching your agency in mistakes. The goal is building confidence that you're evaluating vendor performance accurately despite not being an expert yourself. If the second opinions validate agency quality, you have justified confidence. If they surface concerns, you have specific topics to address.

[INTERNAL: Agency Evaluation Checklist]

## When to Fire Your Agency (and How to Transition)

Not every performance gap justifies termination. SEO timelines are legitimately long. Competitive markets are legitimately difficult. But patterns of behavior indicate when patience has become enabling.

### Knowing the Difference Between Slow Results and Bad Work

**Slow results look like this:** Rankings are improving, but slowly. Traffic is growing, but not at the rate projected. The agency explains competitive dynamics, provides adjusted timelines, and shows evidence that work is accumulating even if results haven't materialized. Metrics are moving in the right direction, just not fast enough.

**Bad work looks like this:** Rankings fluctuate without pattern. Traffic is flat or declining despite reported activity. The agency explains failures with external factors but doesn't propose strategy changes. Metrics aren't moving, or they're moving in ways that don't connect to business outcomes.

The key distinction is trajectory and accountability. Slow results show forward progress with honest acknowledgment of timeline challenges. Bad work shows circular motion with deflection of responsibility.

Red lines that justify immediate termination:

**Google penalties.** If your site receives a **manual penalty** in **Google Search Console**, investigate whether agency tactics caused it. Penalties from link schemes or content manipulation indicate either incompetence or deliberate risk-taking with your asset.

**Undisclosed risks.** If you discover the agency used tactics they didn't disclose—private blog networks, purchased links, cloaking, hidden text—terminate immediately. Beyond the **algorithmic penalty** risk, undisclosed tactics indicate they'll hide other problems.

**Complete strategy misalignment.** If after clear communication about business objectives, the agency continues optimizing for metrics that don't matter to you, they're either unable or unwilling to adjust. Either way, the engagement isn't working.

### Extracting Deliverables and Documentation on Exit

Before terminating, ensure you have access to and copies of:

**All content created.** Blog posts, landing pages, any written deliverables. Verify ownership in your contract—some agencies retain content rights until final payment.

**Technical documentation.** Audit reports, crawl exports, backlink analyses, disavow files. You'll need these to brief a replacement vendor.

**Reporting history.** Historical reports showing what was done and when. This establishes baseline for your next engagement and prevents repeating work.

**Tool access.** If the agency set up tools on your accounts, ensure you have admin credentials. If they used their own tool licenses, request exports of all historical data.

**Vendor and freelancer contacts.** If the agency subcontracted content creation or link building, ask for introductions to those vendors. You may want to continue those relationships directly.

Document everything before announcing termination. Once you've notified the agency, cooperation typically decreases. Get your assets first, then communicate the decision.

### Avoiding Gaps When Switching to In-House or New Vendor

Transition periods create SEO risk. Content production stops. Technical monitoring lapses. Link building campaigns halt mid-execution. Competitors gain ground while you reorganize.

Minimize gaps with overlapping engagement:

**Hire replacement before terminating incumbent.** Brief the new vendor while the current one is still working. Parallel processing costs more but prevents productivity dead zones.

**Document current priorities.** What keywords are being actively targeted? What content is in progress? What technical projects are mid-execution? Your new vendor needs to pick up where the old one stopped, not restart from scratch.

**Maintain monitoring continuity.** Keep **Google Search Console** and **Analytics** access active through the transition. Tracking should never go dark, even if active work pauses.

**Set realistic expectations for new vendor ramp-up.** A new agency needs 30-60 days to audit your current situation, understand your business, and develop strategy. Don't expect immediate output. Budget for onboarding time when planning transition timelines.

**Watch for performance dips.** Transitions often cause temporary ranking fluctuations as strategy changes. Track closely for the first 90 days post-transition. If declines exceed expected variance, address immediately.

The mechanics of firing an agency are straightforward. The risk is losing momentum during the transition and never recovering the ground. Plan the switch to minimize dead time, and you protect the asset investment the previous engagement built—even if that engagement underperformed.

## The Audit Mindset

Auditing your SEO agency isn't adversarial. It's fiduciary responsibility applied to vendor management.

You don't know SEO at practitioner depth, and you don't need to. You need to know whether the money you're spending generates appropriate return, whether the work being done aligns with your business objectives, and whether your vendor operates with transparency and strategic integrity.

The questions and verification approaches in this framework give you that capability without requiring you to become an SEO expert. Run them quarterly. Adjust vendor relationships based on what you find. Over time, you'll develop pattern recognition that makes evaluation faster and more accurate.

Good agencies welcome scrutiny because it differentiates them from vendors who survive on client ignorance. If your questions create defensive reactions or resistance to verification, that tells you something important about the relationship.

You're paying for outcomes. Make sure you can verify you're getting them.

[INTERNAL: SEO for CMOs—Managing SEO Spend When You Can't Measure It Like Paid]
